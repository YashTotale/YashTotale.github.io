[{"name":"user-interface","link":"https://en.wikipedia.org/wiki/User_interface","summary":"In the industrial design field of human-computer interaction, a user interface (UI) is the space where interactions between humans and machines occur. The goal of this interaction is to allow effective operation and control of the machine from the human end, whilst the machine simultaneously feeds back information that aids the operators' decision-making process. Examples of this broad concept of user interfaces include the interactive aspects of computer operating systems, hand tools, heavy machinery operator controls, and process controls. The design considerations applicable when creating user interfaces are related to, or involve such disciplines as, ergonomics and psychology.\nGenerally, the goal of user interface design is to produce a user interface which makes it easy, efficient, and enjoyable (user-friendly) to operate a machine in the way which produces the desired result (i.e. maximum usability). This generally means that the operator needs to provide minimal input to achieve the desired output, and also that the machine minimizes undesired outputs to the user.\nUser interfaces are composed of one or more layers, including a human-machine interface (HMI) that interfaces machines with physical input hardware such as keyboards, mice, or game pads, and output hardware such as computer monitors, speakers, and printers. A device that implements an HMI is called a human interface device (HID). Other terms for human-machine interfaces are man-machine interface (MMI) and, when the machine in question is a computer, human-computer interface. Additional UI layers may interact with one or more human senses, including: tactile UI (touch), visual UI (sight), auditory UI (sound), olfactory UI (smell), equilibrial UI (balance), and gustatory UI (taste).\nComposite user interfaces (CUIs) are UIs that interact with two or more senses. The most common CUI is a graphical user interface (GUI), which is composed of a tactile UI and a visual UI capable of displaying graphics. When sound is added to a GUI, it becomes a multimedia user interface (MUI). There are three broad categories of CUI: standard, virtual and augmented. Standard composite user interfaces use standard human interface devices like keyboards, mice, and computer monitors. When the CUI blocks out the real world to create a virtual reality, the CUI is virtual and uses a virtual reality interface. When the CUI does not block out the real world and creates augmented reality, the CUI is augmented and uses an augmented reality interface. When a UI interacts with all human senses, it is called a qualia interface, named after the theory of qualia. CUI may also be classified by how many senses they interact with as either an X-sense virtual reality interface or X-sense augmented reality interface, where X is the number of senses interfaced with. For example, a Smell-O-Vision is a 3-sense (3S) Standard CUI with visual display, sound and smells; when virtual reality interfaces interface with smells and touch it is said to be a 4-sense (4S) virtual reality interface; and when augmented reality interfaces interface with smells and touch it is said to be a 4-sense (4S) augmented reality interface."},{"name":"user interface","link":"https://en.wikipedia.org/wiki/User_interface","summary":"In the industrial design field of human-computer interaction, a user interface (UI) is the space where interactions between humans and machines occur. The goal of this interaction is to allow effective operation and control of the machine from the human end, whilst the machine simultaneously feeds back information that aids the operators' decision-making process. Examples of this broad concept of user interfaces include the interactive aspects of computer operating systems, hand tools, heavy machinery operator controls, and process controls. The design considerations applicable when creating user interfaces are related to, or involve such disciplines as, ergonomics and psychology.\nGenerally, the goal of user interface design is to produce a user interface which makes it easy, efficient, and enjoyable (user-friendly) to operate a machine in the way which produces the desired result (i.e. maximum usability). This generally means that the operator needs to provide minimal input to achieve the desired output, and also that the machine minimizes undesired outputs to the user.\nUser interfaces are composed of one or more layers, including a human-machine interface (HMI) that interfaces machines with physical input hardware such as keyboards, mice, or game pads, and output hardware such as computer monitors, speakers, and printers. A device that implements an HMI is called a human interface device (HID). Other terms for human-machine interfaces are man-machine interface (MMI) and, when the machine in question is a computer, human-computer interface. Additional UI layers may interact with one or more human senses, including: tactile UI (touch), visual UI (sight), auditory UI (sound), olfactory UI (smell), equilibrial UI (balance), and gustatory UI (taste).\nComposite user interfaces (CUIs) are UIs that interact with two or more senses. The most common CUI is a graphical user interface (GUI), which is composed of a tactile UI and a visual UI capable of displaying graphics. When sound is added to a GUI, it becomes a multimedia user interface (MUI). There are three broad categories of CUI: standard, virtual and augmented. Standard composite user interfaces use standard human interface devices like keyboards, mice, and computer monitors. When the CUI blocks out the real world to create a virtual reality, the CUI is virtual and uses a virtual reality interface. When the CUI does not block out the real world and creates augmented reality, the CUI is augmented and uses an augmented reality interface. When a UI interacts with all human senses, it is called a qualia interface, named after the theory of qualia. CUI may also be classified by how many senses they interact with as either an X-sense virtual reality interface or X-sense augmented reality interface, where X is the number of senses interfaced with. For example, a Smell-O-Vision is a 3-sense (3S) Standard CUI with visual display, sound and smells; when virtual reality interfaces interface with smells and touch it is said to be a 4-sense (4S) virtual reality interface; and when augmented reality interfaces interface with smells and touch it is said to be a 4-sense (4S) augmented reality interface."},{"name":"front-end","link":"https://en.wikipedia.org/wiki/Front_end_and_back_end","summary":"In software engineering, the terms front end and back end refer to the separation of concerns between the presentation layer (front end), and the data access layer (back end) of a piece of software, or the physical infrastructure or hardware. In the client–server model, the client is usually considered the front end and the server is usually considered the back end, even when some presentation work is actually done on the server itself."},{"name":"front end","link":"https://en.wikipedia.org/wiki/Front_end_and_back_end","summary":"In software engineering, the terms front end and back end refer to the separation of concerns between the presentation layer (front end), and the data access layer (back end) of a piece of software, or the physical infrastructure or hardware. In the client–server model, the client is usually considered the front end and the server is usually considered the back end, even when some presentation work is actually done on the server itself."},{"name":"multi-paradigm","link":"https://en.wikipedia.org/wiki/Programming_paradigm","summary":"Programming paradigms are a way to classify programming languages based on their features. Languages can be classified into multiple paradigms.\nSome paradigms are concerned mainly with implications for the execution model of the language, such as allowing side effects, or whether the sequence of operations is defined by the execution model.  Other paradigms are concerned mainly with the way that code is organized, such as grouping a code into units along with the state that is modified by the code.  Yet others are concerned mainly with the style of syntax and grammar.\nCommon programming paradigms include:\nimperative in which the programmer instructs the machine how to change its state,\nprocedural which groups instructions into procedures,\nobject-oriented which groups instructions with the part of the state they operate on,\ndeclarative in which the programmer merely declares properties of the desired result, but not how to compute it\nfunctional in which the desired result is declared as the value of a series of function applications,\nlogic in which the desired result is declared as the answer to a question about a system of facts and rules,\nmathematical in which the desired result is declared as the solution of an optimization problemSymbolic techniques such as reflection, which allow the program to refer to itself, might also be considered as a programming paradigm. However, this is compatible with the major paradigms and thus is not a real paradigm in its own right.\nFor example, languages that fall into the imperative paradigm have two main features: they state the order in which operations occur, with constructs that explicitly control that order, and they allow side effects, in which state can be modified at one point in time, within one unit of code, and then later read at a different point in time inside a different unit of code.  The communication between the units of code is not explicit.  Meanwhile, in object-oriented programming, code is organized into objects that contain a state that is only modified by the code that is part of the object.  Most object-oriented languages are also imperative languages.  In contrast, languages that fit the declarative paradigm do not state the order in which to execute operations.  Instead, they supply a number of available operations in the system, along with the conditions under which each is allowed to execute.  The implementation of the language's execution model tracks which operations are free to execute and chooses the order independently. More at  Comparison of multi-paradigm programming languages.\n\n"},{"name":"multi paradigm","link":"https://en.wikipedia.org/wiki/Programming_paradigm","summary":"Programming paradigms are a way to classify programming languages based on their features. Languages can be classified into multiple paradigms.\nSome paradigms are concerned mainly with implications for the execution model of the language, such as allowing side effects, or whether the sequence of operations is defined by the execution model.  Other paradigms are concerned mainly with the way that code is organized, such as grouping a code into units along with the state that is modified by the code.  Yet others are concerned mainly with the style of syntax and grammar.\nCommon programming paradigms include:\nimperative in which the programmer instructs the machine how to change its state,\nprocedural which groups instructions into procedures,\nobject-oriented which groups instructions with the part of the state they operate on,\ndeclarative in which the programmer merely declares properties of the desired result, but not how to compute it\nfunctional in which the desired result is declared as the value of a series of function applications,\nlogic in which the desired result is declared as the answer to a question about a system of facts and rules,\nmathematical in which the desired result is declared as the solution of an optimization problemSymbolic techniques such as reflection, which allow the program to refer to itself, might also be considered as a programming paradigm. However, this is compatible with the major paradigms and thus is not a real paradigm in its own right.\nFor example, languages that fall into the imperative paradigm have two main features: they state the order in which operations occur, with constructs that explicitly control that order, and they allow side effects, in which state can be modified at one point in time, within one unit of code, and then later read at a different point in time inside a different unit of code.  The communication between the units of code is not explicit.  Meanwhile, in object-oriented programming, code is organized into objects that contain a state that is only modified by the code that is part of the object.  Most object-oriented languages are also imperative languages.  In contrast, languages that fit the declarative paradigm do not state the order in which to execute operations.  Instead, they supply a number of available operations in the system, along with the conditions under which each is allowed to execute.  The implementation of the language's execution model tracks which operations are free to execute and chooses the order independently. More at  Comparison of multi-paradigm programming languages.\n\n"},{"name":"back-end","link":"https://en.wikipedia.org/wiki/Front_end_and_back_end","summary":"In software engineering, the terms front end and back end refer to the separation of concerns between the presentation layer (front end), and the data access layer (back end) of a piece of software, or the physical infrastructure or hardware. In the client–server model, the client is usually considered the front end and the server is usually considered the back end, even when some presentation work is actually done on the server itself."},{"name":"back end","link":"https://en.wikipedia.org/wiki/Front_end_and_back_end","summary":"In software engineering, the terms front end and back end refer to the separation of concerns between the presentation layer (front end), and the data access layer (back end) of a piece of software, or the physical infrastructure or hardware. In the client–server model, the client is usually considered the front end and the server is usually considered the back end, even when some presentation work is actually done on the server itself."},{"name":"first-class functions","link":"https://en.wikipedia.org/wiki/First-class_function","summary":"In computer science, a programming language is said to have first-class functions if it treats functions as first-class citizens. This means the language supports passing functions as arguments to other functions, returning them as the values from other functions, and assigning them to variables or storing them in data structures. Some programming language theorists require support for anonymous functions (function literals) as well. In languages with first-class functions, the names of functions do not have any special status; they are treated like ordinary variables with a function type. The term was coined by Christopher Strachey in the context of \"functions as first-class citizens\" in the mid-1960s.First-class functions are a necessity for the functional programming style, in which the use of higher-order functions is a standard practice. A simple example of a higher-ordered function is the map function, which takes, as its arguments, a function and a list, and returns the list formed by applying the function to each member of the list. For a language to support map, it must support passing a function as an argument.\nThere are certain implementation difficulties in passing functions as arguments or returning them as results, especially in the presence of non-local variables introduced in nested and anonymous functions. Historically, these were termed the funarg problems, the name coming from \"function argument\". In early imperative languages these problems were avoided by either not supporting functions as result types (e.g. ALGOL 60, Pascal) or omitting nested functions and thus non-local variables (e.g. C). The early functional language Lisp took the approach of dynamic scoping, where non-local variables refer to the closest definition of that variable at the point where the function is executed, instead of where it was defined. Proper support for lexically scoped first-class functions was introduced in Scheme and requires handling references to functions as closures instead of bare function pointers, which in turn makes garbage collection a necessity."},{"name":"first class functions","link":"https://en.wikipedia.org/wiki/First-class_function","summary":"In computer science, a programming language is said to have first-class functions if it treats functions as first-class citizens. This means the language supports passing functions as arguments to other functions, returning them as the values from other functions, and assigning them to variables or storing them in data structures. Some programming language theorists require support for anonymous functions (function literals) as well. In languages with first-class functions, the names of functions do not have any special status; they are treated like ordinary variables with a function type. The term was coined by Christopher Strachey in the context of \"functions as first-class citizens\" in the mid-1960s.First-class functions are a necessity for the functional programming style, in which the use of higher-order functions is a standard practice. A simple example of a higher-ordered function is the map function, which takes, as its arguments, a function and a list, and returns the list formed by applying the function to each member of the list. For a language to support map, it must support passing a function as an argument.\nThere are certain implementation difficulties in passing functions as arguments or returning them as results, especially in the presence of non-local variables introduced in nested and anonymous functions. Historically, these were termed the funarg problems, the name coming from \"function argument\". In early imperative languages these problems were avoided by either not supporting functions as result types (e.g. ALGOL 60, Pascal) or omitting nested functions and thus non-local variables (e.g. C). The early functional language Lisp took the approach of dynamic scoping, where non-local variables refer to the closest definition of that variable at the point where the function is executed, instead of where it was defined. Proper support for lexically scoped first-class functions was introduced in Scheme and requires handling references to functions as closures instead of bare function pointers, which in turn makes garbage collection a necessity."},{"name":"prototype-based","link":"https://en.wikipedia.org/wiki/Prototype-based_programming","summary":"Prototype-based programming is a style of object-oriented programming in which behaviour reuse (known as inheritance) is performed via a process of reusing existing objects that serve as prototypes. This model can also be known as prototypal, prototype-oriented, classless, or instance-based programming.\nPrototype-based programming uses generalized objects, which can then be cloned and extended. Using fruit as an example, a \"fruit\" object would represent the properties and functionality of fruit in general. A \"banana\" object would be cloned from the \"fruit\" object and general properties specific to bananas would be appended. Each individual \"banana\" object would be cloned from the generic \"banana\" object. Compare to the class-based paradigm, where a \"fruit\" class would be extended by a \"banana\" class.\nThe first prototype-oriented programming language was Self, developed by David Ungar and Randall Smith in the mid-1980s to research topics in object-oriented language design. Since the late 1990s, the classless paradigm has grown increasingly popular. Some current prototype-oriented languages are JavaScript (and other ECMAScript implementations such as JScript and Flash's ActionScript 1.0), Lua, Cecil, NewtonScript, Io, Ioke, MOO, REBOL and AHK.\n\n"},{"name":"prototype based","link":"https://en.wikipedia.org/wiki/Prototype-based_programming","summary":"Prototype-based programming is a style of object-oriented programming in which behaviour reuse (known as inheritance) is performed via a process of reusing existing objects that serve as prototypes. This model can also be known as prototypal, prototype-oriented, classless, or instance-based programming.\nPrototype-based programming uses generalized objects, which can then be cloned and extended. Using fruit as an example, a \"fruit\" object would represent the properties and functionality of fruit in general. A \"banana\" object would be cloned from the \"fruit\" object and general properties specific to bananas would be appended. Each individual \"banana\" object would be cloned from the generic \"banana\" object. Compare to the class-based paradigm, where a \"fruit\" class would be extended by a \"banana\" class.\nThe first prototype-oriented programming language was Self, developed by David Ungar and Randall Smith in the mid-1980s to research topics in object-oriented language design. Since the late 1990s, the classless paradigm has grown increasingly popular. Some current prototype-oriented languages are JavaScript (and other ECMAScript implementations such as JScript and Flash's ActionScript 1.0), Lua, Cecil, NewtonScript, Io, Ioke, MOO, REBOL and AHK.\n\n"},{"name":"open-source","link":"https://en.wikipedia.org/wiki/Open_source","summary":"Open source is a source code that is made freely available for possible modification and redistribution. Products include permission to use the source code, design documents, or content of the product. It most commonly refers to the open-source model, in which open-source software or other products are released under an open-source license as part of the open-source-software movement. Use of the term originated with software, but has expanded beyond the software sector to cover other open content and forms of open collaboration."},{"name":"open source","link":"https://en.wikipedia.org/wiki/Open_source","summary":"Open source is a source code that is made freely available for possible modification and redistribution. Products include permission to use the source code, design documents, or content of the product. It most commonly refers to the open-source model, in which open-source software or other products are released under an open-source license as part of the open-source-software movement. Use of the term originated with software, but has expanded beyond the software sector to cover other open content and forms of open collaboration."}]